{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽï¸ Accel-Driv â†’ 3D Gaussian Splatting Training\n",
    "\n",
    "Train a 3DGS model from multi-view renders exported by the Track Suite editor.\n",
    "\n",
    "**Requirements:** Colab Pro (GPU runtime â€” T4 minimum, A100 recommended)\n",
    "\n",
    "## Pipeline\n",
    "1. Upload `training_views.zip` from the editor's Splat tab â†’ Export Training Views\n",
    "2. Install nerfstudio + gsplat\n",
    "3. Train splatfacto model\n",
    "4. Export `.ply` â†’ download â†’ load back in Track Suite Splat tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU & Install nerfstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!nvidia-smi\nimport torch\nprint(f\"PyTorch {torch.__version__}, CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    props = torch.cuda.get_device_properties(0)\n    vram = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)\n    print(f\"VRAM: {vram / 1e9:.1f} GB\")\nelse:\n    raise RuntimeError(\"No GPU detected! Go to Runtime â†’ Change runtime type â†’ GPU\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nerfstudio (includes splatfacto and gsplat)\n",
    "!pip install -q nerfstudio\n",
    "print(\"\\nâœ… nerfstudio installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Download & extract training views"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, zipfile, json\nfrom pathlib import Path\n\nDATA_DIR = Path(\"/content/training_data\")\n\n# Download training_views.zip from GitHub repo\nZIP_URL = \"https://github.com/phdev/accel-driv/raw/main/training_views.zip\"\nZIP_PATH = \"/content/training_views.zip\"\n\nprint(\"Downloading training_views.zip from GitHub...\")\n!wget -q -O {ZIP_PATH} \"{ZIP_URL}\"\nassert os.path.exists(ZIP_PATH) and os.path.getsize(ZIP_PATH) > 0, \"Download failed!\"\n\n# Extract\nif DATA_DIR.exists():\n    !rm -rf {DATA_DIR}\nDATA_DIR.mkdir(parents=True)\n\nwith zipfile.ZipFile(ZIP_PATH, 'r') as z:\n    z.extractall(DATA_DIR)\n\n# Verify\ntransforms_path = DATA_DIR / \"transforms.json\"\nassert transforms_path.exists(), \"transforms.json not found in ZIP!\"\n\nwith open(transforms_path) as f:\n    tf = json.load(f)\n\nn_frames = len(tf[\"frames\"])\nprint(f\"\\nâœ… Extracted {n_frames} frames at {tf['w']}x{tf['h']}px\")\nprint(f\"   Focal length: {tf['fl_x']:.1f}px\")\nprint(f\"   Images dir: {DATA_DIR / 'images'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a few training views\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "img_dir = DATA_DIR / \"images\"\n",
    "imgs = sorted(img_dir.glob(\"*.png\"))\n",
    "\n",
    "fig, axes = plt.subplots(1, min(5, len(imgs)), figsize=(20, 4))\n",
    "if not hasattr(axes, '__len__'): axes = [axes]\n",
    "step = max(1, len(imgs) // 5)\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = i * step\n",
    "    if idx < len(imgs):\n",
    "        ax.imshow(Image.open(imgs[idx]))\n",
    "        ax.set_title(imgs[idx].name, fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(f\"{len(imgs)} training views\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train splatfacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Training Config { display-mode: \"form\" }\n",
    "MAX_STEPS = 15000  #@param {type:\"slider\", min:5000, max:30000, step:1000}\n",
    "NUM_SPLATS = 500000  #@param [100000, 250000, 500000, 1000000] {type:\"raw\"}\n",
    "OUTPUT_DIR = \"/content/outputs\"\n",
    "\n",
    "print(f\"Training splatfacto for {MAX_STEPS} steps with up to {NUM_SPLATS:,} splats\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "!ns-train splatfacto \\\n",
    "    --data {DATA_DIR} \\\n",
    "    --output-dir {OUTPUT_DIR} \\\n",
    "    --max-num-iterations {MAX_STEPS} \\\n",
    "    --pipeline.model.num-random {NUM_SPLATS} \\\n",
    "    --vis none \\\n",
    "    nerfstudio-data \\\n",
    "    --train-split-fraction 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export .ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Find the latest checkpoint\n",
    "config_files = sorted(glob.glob(f\"{OUTPUT_DIR}/**/config.yml\", recursive=True))\n",
    "assert config_files, \"No training output found! Did training complete?\"\n",
    "config_path = config_files[-1]\n",
    "print(f\"Using config: {config_path}\")\n",
    "\n",
    "PLY_OUTPUT = \"/content/splat_export.ply\"\n",
    "\n",
    "!ns-export gaussian-splat \\\n",
    "    --load-config {config_path} \\\n",
    "    --output-dir /content/export_tmp\n",
    "\n",
    "# Find the exported ply\n",
    "exported = sorted(glob.glob(\"/content/export_tmp/**/*.ply\", recursive=True))\n",
    "if exported:\n",
    "    import shutil\n",
    "    shutil.move(exported[0], PLY_OUTPUT)\n",
    "    size_mb = os.path.getsize(PLY_OUTPUT) / 1e6\n",
    "    print(f\"\\nâœ… Exported: {PLY_OUTPUT} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"âŒ No .ply found in export output\")\n",
    "    !ls -la /content/export_tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download .ply\n",
    "\n",
    "Download the `.ply` file, then load it back in the Track Suite editor:\n",
    "**Splat tab â†’ Preview and Load Splat â†’ Load File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "if os.path.exists(PLY_OUTPUT):\n",
    "    files.download(PLY_OUTPUT)\n",
    "    print(\"Downloading splat_export.ply â€” load it in Track Suite Splat tab!\")\n",
    "else:\n",
    "    print(\"No .ply file to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Optional: Convert to .splat (smaller, faster loading)\n",
    "\n",
    "If the .ply is too large, convert to compressed `.splat` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: convert PLY to compressed .splat format\n",
    "# Requires antimatter15's splat converter\n",
    "!pip install -q plyfile numpy\n",
    "\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import struct\n",
    "\n",
    "def ply_to_splat(ply_path, splat_path):\n",
    "    \"\"\"Convert 3DGS .ply to .splat (compact binary format).\"\"\"\n",
    "    ply = PlyData.read(ply_path)\n",
    "    v = ply['vertex']\n",
    "    n = len(v)\n",
    "    print(f\"Converting {n:,} gaussians...\")\n",
    "\n",
    "    # .splat format: per-gaussian 32 bytes\n",
    "    # [x,y,z] float32 (12) + [scale_0,1,2] float16 (6) + [r,g,b,a] uint8 (4)\n",
    "    # + [rot_0,1,2,3] uint8 (4) + [opacity] float16 (2) + padding (4) = 32\n",
    "    # Actually the antimatter format is simpler â€” just positions + SH + scales + rot\n",
    "    # For now, just download the .ply â€” Spark.js handles it directly.\n",
    "\n",
    "    print(f\"\\nNote: Spark.js in the editor loads .ply natively.\")\n",
    "    print(f\"For smaller files, use SuperSplat (supersplat.io) to convert to .sog format.\")\n",
    "\n",
    "ply_to_splat(PLY_OUTPUT, \"/content/output.splat\")"
   ]
  }
 ]
}